{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "462d9687",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import time, requests, os, re, random\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import WebDriverException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be1c25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trails_url = 'https://www.alltrails.com/us/washington'\n",
    "num_trails = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "55dd4eb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bh/c8vgcl4518l2jtlcnl312lt00000gn/T/ipykernel_74831/853799868.py:14: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  browser = webdriver.Chrome(chromedriver, options=option)\n"
     ]
    }
   ],
   "source": [
    "chromedriver = '/Applications/chromedriver'\n",
    "os.environ[\"webdriver.chrome.driver\"] = chromedriver\n",
    "\n",
    "option = webdriver.ChromeOptions()\n",
    "option.add_argument('--disable-blink-features=AutomationControlled')\n",
    "option.add_argument(\"--incognito\")\n",
    "option.add_argument(\"--disable-plugins-discovery\")\n",
    "option.add_argument(\"--start-maximized\")\n",
    "option.add_argument('--single-process')\n",
    "option.add_experimental_option('useAutomationExtension', False)\n",
    "option.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "\n",
    "option.add_argument(\"user-agent=Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/99.0.4844.51 Safari/537.36\")\n",
    "browser = webdriver.Chrome(chromedriver, options=option)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e1264a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.get('https://www.alltrails.com/login')\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7a9ebdbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bh/c8vgcl4518l2jtlcnl312lt00000gn/T/ipykernel_74831/2238880594.py:1: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  email = browser.find_element_by_name('userEmail')\n",
      "/var/folders/bh/c8vgcl4518l2jtlcnl312lt00000gn/T/ipykernel_74831/2238880594.py:5: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  pwd = browser.find_element_by_name('userPassword')\n",
      "/var/folders/bh/c8vgcl4518l2jtlcnl312lt00000gn/T/ipykernel_74831/2238880594.py:10: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  browser.find_element_by_xpath(\"//input[@type='submit']\").click()\n"
     ]
    }
   ],
   "source": [
    "email = browser.find_element_by_name('userEmail')\n",
    "email.send_keys('nat.goodby@gmail.com')\n",
    "time.sleep(1)\n",
    "\n",
    "pwd = browser.find_element_by_name('userPassword')\n",
    "pwd.send_keys('9D2J2c7wrg^j')\n",
    "pwd.submit\n",
    "time.sleep(1)\n",
    "\n",
    "browser.find_element_by_xpath(\"//input[@type='submit']\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa4ada0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trail_urls(browser, trails_url, num_trails):\n",
    "    time.sleep(1)\n",
    "    browser.get(trails_url)\n",
    "    \n",
    "    count = num_trails / 10\n",
    "    while count > 1:\n",
    "        button = browser.find_element_by_xpath(\"//button[@title='Show more trails']\")\n",
    "        time.sleep(1)\n",
    "        try:\n",
    "            button.click()\n",
    "            count -= 1\n",
    "            time.sleep(1)\n",
    "            browser.execute_script(\"window.stop();\")\n",
    "            \n",
    "        except NoSuchElementException:\n",
    "            time.sleep(1)\n",
    "            browser.execute_script(\"window.stop();\")\n",
    "    \n",
    "    url_list = []\n",
    "    urls = browser.find_elements_by_xpath(\"//*[@class='xlate-none styles-module__link___EEZXn']\")\n",
    "    for url in urls:\n",
    "        next_url = url.get_attribute(\"href\")\n",
    "        url_list.append(next_url)\n",
    "    return url_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385a2198",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "url_list = get_trail_urls(browser, trails_url, num_trails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a1d8b7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define functions to scape desired info from each webpage\n",
    "\n",
    "def get_trail_name(soup):\n",
    "    try:\n",
    "        trail_name = soup.find(class_ = 'xlate-none styles-module__name___pgMB8').text\n",
    "    except AttributeError:\n",
    "        trail_name = None  \n",
    "    return trail_name\n",
    "\n",
    "def get_difficulty(soup):\n",
    "    try:\n",
    "        difficulty = soup.find(class_ = 'styles-module__info___jMR_5 styles-module__thin___SHeMO').next.text    \n",
    "    except AttributeError:\n",
    "        difficulty = None\n",
    "    return difficulty\n",
    "    \n",
    "def get_distance(soup):\n",
    "    try:\n",
    "        distance = soup.find_all(class_ = 'styles-module__detailData___fxmwv')[0].text\n",
    "        re.sub('[^\\d\\.]','', distance)\n",
    "    except AttributeError:\n",
    "        distance = None\n",
    "    except IndexError:\n",
    "        distance = None\n",
    "    return distance\n",
    "\n",
    "def get_elevation_gain(soup):\n",
    "    try:\n",
    "        elevation_gain = soup.find_all(class_ = 'styles-module__detailData___fxmwv')[1].text\n",
    "        re.sub('[^0-9]','', elevation_gain)\n",
    "    except AttributeError:\n",
    "        elevation_gain = None\n",
    "    except IndexError:\n",
    "        elevation_gain = None\n",
    "    return elevation_gain\n",
    "\n",
    "def get_route_type(soup):\n",
    "    try:\n",
    "        route_type = soup.find_all(class_ = 'styles-module__detailData___fxmwv')[2].text\n",
    "    except AttributeError:\n",
    "        route_type = None\n",
    "    except IndexError:\n",
    "        route_type = None\n",
    "    return route_type\n",
    "    \n",
    "def get_num_completed(soup):\n",
    "    try:\n",
    "        num_completed = soup.find_all(class_='MuiTab-wrapper styles-module__tabWrapper___QY_wC')[-1].text\n",
    "        re.sub('[^0-9]','', num_completed)\n",
    "    except AttributeError:\n",
    "        num_completed = None\n",
    "    except IndexError:\n",
    "        num_completed = None\n",
    "    return num_completed\n",
    "\n",
    "def get_activities(soup):\n",
    "    try:\n",
    "        activities = soup.find_all(class_='MuiTab-wrapper styles-module__tabWrapper___QY_wC')[-2].text\n",
    "        re.sub('[^0-9]','', activities)\n",
    "    except AttributeError:\n",
    "        activities = None\n",
    "    except IndexError:\n",
    "        activities = None\n",
    "    return activities\n",
    "\n",
    "def get_photos(soup):\n",
    "    try:\n",
    "        photos = soup.find_all(class_='MuiTab-wrapper styles-module__tabWrapper___QY_wC')[-3].text\n",
    "        re.sub('[^0-9]','', photos)\n",
    "    except AttributeError:\n",
    "        photos = None\n",
    "    except IndexError:\n",
    "        photos = None\n",
    "    return photos\n",
    "\n",
    "def get_reviews(soup):\n",
    "    try:\n",
    "        reviews = soup.find_all(class_='MuiTab-wrapper styles-module__selectedTabWrapper___Rpj4b')[-1].text\n",
    "        re.sub('[^0-9]','', reviews)\n",
    "    except AttributeError:\n",
    "        reviews = None\n",
    "    except IndexError:\n",
    "        reviews = None\n",
    "    return reviews\n",
    "\n",
    "\n",
    "def get_tags_list(soup):\n",
    "    tags = soup.find_all(class_='big rounded active')\n",
    "    list_of_tags = []\n",
    "    for tag in tags:\n",
    "        try:\n",
    "            list_of_tags.append(tag.text)\n",
    "        except AttributeError:\n",
    "            continue\n",
    "    return list_of_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22cb30a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_data(url_list):\n",
    "    trail_info = []\n",
    "    for count, url in enumerate(url_list):\n",
    "        time.sleep(.5+2*random.random())\n",
    "    \n",
    "        try:\n",
    "            browser.get(url)\n",
    "            page = browser.page_source\n",
    "            soup = bs(page)\n",
    "            \n",
    "            trail_dict = {'trail_name':get_trail_name(soup),\n",
    "                      'difficulty':get_difficulty(soup),\n",
    "                      'distance':get_distance(soup),\n",
    "                      'elevation_gain':get_elevation_gain(soup),\n",
    "                      'route_type':get_route_type(soup),\n",
    "                      'num_completed':get_num_completed(soup),\n",
    "                      'activities':get_activities(soup),\n",
    "                      'photos':get_photos(soup),\n",
    "                      'reviews':get_reviews(soup),\n",
    "                      'tags':get_tags_list(soup)}\n",
    "            trail_info.append(trail_dict)\n",
    "            print(f\"Trail number {count+1}: {trail_dict['trail_name']}\")\n",
    "            browser.execute_script(\"window.stop();\")\n",
    "        \n",
    "        except NoSuchElementException:\n",
    "            time.sleep(5)\n",
    "            browser.execute_script(\"window.stop();\")\n",
    "            \n",
    "        except WebDriverException:\n",
    "            browser.switch_to.default_content()\n",
    "            time.sleep(5)\n",
    "            browser.execute_script(\"window.stop();\")\n",
    "        \n",
    "        if (count % 25 == 0):\n",
    "            trail_df = pd.DataFrame(trail_info)\n",
    "            trail_df.to_pickle('trails_df.pkl')\n",
    "            time.sleep(10)\n",
    "            \n",
    "    trail_df = pd.DataFrame(trail_info)\n",
    "    trail_df.to_pickle('trails_df.pkl')\n",
    "    print(f\"The dataframe includes data for {len(trail_df)} trails\")\n",
    "    return trail_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5123c88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "scrape_data(url_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb08b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = pd.Series(url_list, name = 'url')\n",
    "name_and_url = pd.concat([trail_df['trail_name'], url], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04246941",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_urls = name_and_url[name_and_url['trail_name'].isna()]['url'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3557da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_failed_trails(missing_urls):\n",
    "    \"\"\"\n",
    "    Function to scrape info for trails that failed during first pass because of RECAPTCHA.\n",
    "    \"\"\"   \n",
    "    all_trails = pd.read_pickle('trails_df.pkl')\n",
    "    trail_info = []\n",
    "    for count, url in enumerate(missing_urls):\n",
    "        time.sleep(.5+2*random.random())\n",
    "    \n",
    "        try:\n",
    "            browser.get(url)\n",
    "            page = browser.page_source\n",
    "            soup = bs(page)\n",
    "            \n",
    "            trail_dict = {'trail_name':get_trail_name(soup),\n",
    "                      'difficulty':get_difficulty(soup),\n",
    "                      'distance':get_distance(soup),\n",
    "                      'elevation_gain':get_elevation_gain(soup),\n",
    "                      'route_type':get_route_type(soup),\n",
    "                      'num_completed':get_num_completed(soup),\n",
    "                      'activities':get_activities(soup),\n",
    "                      'photos':get_photos(soup),\n",
    "                      'reviews':get_reviews(soup),\n",
    "                      'tags':get_tags_list(soup)}\n",
    "            all_trails = all_trails.append(trail_dict, ignore_index=True)\n",
    "            print(f\"Trail number {count+1}: {trail_dict['trail_name']}\")\n",
    "            name_and_url['trail_name'] = trail_dict['trail_name']\n",
    "            browser.execute_script(\"window.stop();\")\n",
    "        \n",
    "        except NoSuchElementException:\n",
    "            time.sleep(5)\n",
    "            browser.execute_script(\"window.stop();\")\n",
    "            \n",
    "        except WebDriverException:\n",
    "            browser.switch_to.default_content()\n",
    "            time.sleep(5)\n",
    "            browser.execute_script(\"window.stop();\")\n",
    "        \n",
    "        if (count % 10 == 0):\n",
    "            time.sleep(10)\n",
    "       \n",
    "    all_trails.to_pickle('trails_df.pkl')\n",
    "    print(f\"There are now {all_trails['trail_name'].isnull().sum()} trails without info.\")\n",
    "    return all_trails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e606359",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_failed_trails(missing_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a25e9b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a17712cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_list = pd.read_pickle('url_list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e8c548b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_urls = url_list.loc[596:599]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e24551e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bh/c8vgcl4518l2jtlcnl312lt00000gn/T/ipykernel_74831/2087163418.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  all_trails = all_trails.append(trail_dict, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trail number 1: Lacamas Lake Heritage Trail\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bh/c8vgcl4518l2jtlcnl312lt00000gn/T/ipykernel_74831/2087163418.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  all_trails = all_trails.append(trail_dict, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trail number 2: Five Mile Drive\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bh/c8vgcl4518l2jtlcnl312lt00000gn/T/ipykernel_74831/2087163418.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  all_trails = all_trails.append(trail_dict, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trail number 3: Lake Lillian Trail\n",
      "Trail number 4: Little Mountain Park Loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bh/c8vgcl4518l2jtlcnl312lt00000gn/T/ipykernel_74831/2087163418.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  all_trails = all_trails.append(trail_dict, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "all_trails = pd.read_pickle('trails_df.pkl')\n",
    "\n",
    "for count, url in enumerate(extra_urls):\n",
    "    time.sleep(.5+2*random.random())\n",
    "    try:\n",
    "        browser.get(url)\n",
    "        page = browser.page_source\n",
    "        soup = bs(page)\n",
    "            \n",
    "        trail_dict = {'trail_name':get_trail_name(soup),\n",
    "                    'difficulty':get_difficulty(soup),\n",
    "                    'distance':get_distance(soup),\n",
    "                    'elevation_gain':get_elevation_gain(soup),\n",
    "                    'route_type':get_route_type(soup),\n",
    "                    'num_completed':get_num_completed(soup),\n",
    "                    'activities':get_activities(soup),\n",
    "                    'photos':get_photos(soup),\n",
    "                    'reviews':get_reviews(soup),\n",
    "                    'tags':get_tags_list(soup)}\n",
    "        all_trails = all_trails.append(trail_dict, ignore_index=True)\n",
    "        print(f\"Trail number {count+1}: {trail_dict['trail_name']}\")\n",
    "        browser.execute_script(\"window.stop();\")\n",
    "        \n",
    "    except NoSuchElementException:\n",
    "        time.sleep(5)\n",
    "        browser.execute_script(\"window.stop();\")\n",
    "            \n",
    "    except WebDriverException:\n",
    "        browser.switch_to.default_content()\n",
    "        time.sleep(5)\n",
    "        browser.execute_script(\"window.stop();\")\n",
    "       \n",
    "all_trails.to_pickle('all_trails_complete.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c879ed3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 ('metis': conda)",
   "language": "python",
   "name": "python3910jvsc74a57bd07672f80c3280fa3c66bc7c624005d50f40f0808630965f3f9728f4a5965af3d1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
